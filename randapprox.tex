\documentclass[language=ngerman,algolist]{TemplateLecture}

\renewcommand{\LectureName}{Randomisierte und Approximative Algorithmen}
\renewcommand{\ProfName}{Prof. Dr. Thomas Kesselheim, \\ Prof. Dr. Heiko Röglin}
%\renewcommand{\ProfNameShort}{Profs. Kesselheim, Röglin}
\renewcommand{\Semester}{Winter 2025/26}
\renewcommand{\mName}{Daniel Emse}


\begin{document}
\setcounter{chapter}{0}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 2025 / 10 / 14 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\part{Randomisierte und Approximative Algorithmen}

\chapter{Einleitung}
\begin{defi}{Optimierungsproblem, Approximationsalgorithmus}{optimizationProblemApproxAlgo}
    Ein \emph{Optimierungsproblem} $\Pi$ besteht aus
    \begin{itemize}
        \item einer Meinge von Instanzen $\cI_\Pi$
        \item für jede Instanz $ I \in \cI_\Pi$
        \begin{itemize}
            \item einer Menge $\cS_I$ von Lösungen
            \item einer Zielfunktion $f_I: \cS_I \to \IR_{\geq 0}$.
        \end{itemize} 
    \end{itemize}
    Ein \emph{Approximationsalgorithmus} nimmt $I$ als Eingabe und berechnet $A(I) \in \cS_I$ (in polynomieller Zeit).

    Sei $w_A(I) = f_I(A(I))$. Ein Approximationsalgorithmus erreicht Approximationsfaktor $r$, falls 
    \begin{equation*}
        w_A(I) \leq r \cdot \OPT(I) \quad \forall I \in \cI_\Pi \quad \quad \text{(für Minimierungsprobleme)},
    \end{equation*}
    bzw.
    \begin{equation*}
        w_A(I) \geq \frac{1}{r} \cdot \OPT(I) \quad \forall I \in \cI_\Pi \quad \quad \text{(für Maximierungsprobleme)}.
    \end{equation*}
\end{defi}

\chapter{Greedy-Algorithmen}

\section{Vertex Cover}
\newLecture{14.10.2025}


\begin{prob}{Vertex Cover}{VertexCover}
    \prblmObj{Ungerichteter Graph $G = (V, E)$}{Alle $V' \subseteq V$, sodass $\forall e = (u, v) \in E$ gilt $u \in V'$ oder $v \in V'$}{Minimiere $\abs{V'}$}\index{Vertex Cover}
\end{prob}




\begin{defi}{Matching}{Matching}
    Ein \emph{Matching}\index{Matching} $M \subseteq E$ eines Graphen $G = (V, E)$ ist eine Teilmenge der Kanten, sodass es keinen Knoten gibt, der zu mehr als einer Kante aus $M$ inzident ist.

    Es heißt \emph{inklusionsmaximal}\index{Matching!inklusionsmaximales -}, wenn für alle Kanten $e \in E \setminus M$ gilt: $M \cup \set{e}$ ist kein Matching.
\end{defi}
\begin{algorithm}[h]
    \caption{\textsc{Matching-VC}}\label{alg:matching-vc}\index{Matching-VC}
    \begin{algorithmic}[1] % Matching-VC
        \Input{ungerichteter Graph $G = (V, E)$}
        \Output{Vertex Cover $V' \subseteq V$ mit $\abs{V'} \leq 2 \cdot \OPT(G)$}
        \LComment{Berechne inklusionsmaximales Matching $M \subseteq E$:}
        \State{} $M := \emptyset$
        \ForAll{$e = \set{u, v} \in E$}
            \If{weder $u$ noch $v$ ist inzident zu einer Kante in $M$}
                \State{} $M := M \cup \set{e}$
            \EndIf{}
        \EndFor{}
        \State{} $V(M) := \set{v \in V \mid \text{$v$ ist inzident zu einer Kante in $M$}}$
        \State{} \Return{$V(M)$}
    \end{algorithmic}
\end{algorithm}


\begin{thm}{Matching-VC}{MatchingVC}
    Matching-VC hat Laufzeit $\cO(\abs{V} + \abs{E})$ für Graphen in Adjazenzlistendarstellung. Er berechnet ein Vertex Cover der Größe höchstens $2 \cdot \OPT(G)$, wobei $\OPT(G)$ die Größe des kleinsten Vertex Covers ist.
\end{thm}

\begin{proof}
    \begin{description}
        \item[Laufzeit:] In Schritt 1 wird jede Kante genau einmal betrachtet, $\cO(\abs{V} + \abs{E})$. 
        
        In Schritt 2 wird jeder Knoten höchstens einmal betrachtet, $\cO(\abs{V})$. Gemeinsam ergibt sich $\cO(\abs{V} + \abs{E})$.
        \item[Korrektheit:] Angenommen, $e = (u,v) \in E$ wurde nicht von $V(M)$ abgedeckt. Das heißt, es wären weder $u \in V(M)$ noch $v \in V(M)$. Dann wäre $M \cup \set{e}$ ein Matching und $e$ würde in Schritt 1 zu $M$ hinzugefügt werden. Widerspruch zur Inklusionsmaximalität von $M$. Also ist $V(M)$ ein Vertex Cover.
        \item[Approximation:] Sei $V^*$ ein minimales Vertex Cover. $V^*$ muss alle Kanten $e \in E$ abdecken, also auch alle $e \in M$. 
        
        Außerdem haben in $M$ keine zwei Kanten denselben Endpunkt. Deshalb ist $\abs{M} \leq \abs{V^*}$. 
        
        Für unsere Lösung gilt $\abs{V(M)} = 2 \cdot \abs{M} \leq 2 \cdot \OPT(G)$.
    \end{description}
\end{proof}

\section{Set Cover}

\begin{prob}{Set Cover}{SetCover}
    \prblmObj{Menge $S$ mit $n$ Elementen, $n$ Teilmengen $S_1, \ldots, S_m \subseteq S$ mit $\bigcup_{i=1}^m S_i = S$, Kosten $c_1, \ldots, c_m \in \IN$.}{Alle $A \subseteq \set{1, \ldots, m}$ mit $\bigcup_{i \in A} S_i = S$}{Minimiere $\sum_{i \in A} c_i$}\index{Set Cover}
\end{prob}


\begin{algorithm}[h] % Greedy-SC
    \caption{\textsc{Greedy-SC}}\label{alg:greedySC}\index{Greedy-SC}
    \begin{algorithmic}[1]
        \Input{Grundmenge $S$ mit $n$ Elementen, $n$ Teilmengen $S_1, \ldots, S_m \subseteq S$ mit $\bigcup_{i=1}^m S_i = S$, Kosten $c_1, \ldots, c_m \in \IN$.}
        \Output{$A \subseteq \set{1, \ldots, m}$ mit $\bigcup_{i \in A} S_i = S$ und $\sum_{i \in A} c_i$ minimal}
        \State{} $A := \emptyset, C := \emptyset$
        \While{$C \neq S$}
            \State{} Wähle $S_i$ mit minimalen relativen Kosten $r_i(C) = \frac{c_i}{\abs{S_i \setminus C}}$
            \State{} Setze $\price(x) := r_i(C)$ für alle $x \in S_i \setminus C$
            \State{} $A := A \cup \set{i}$
            \State{} $C := C \cup S_i$
        \EndWhile{}
        \State{} \Return{$A$}
    \end{algorithmic}
\end{algorithm}

\begin{thm}{Greedy-SC}{greedySC}
    \textsc{Greedy-SC} ist ein $H_n$-Approximationsalgorithmus für Set Cover, wobei
    \begin{equation*}
        H_n = \sum_{i = 1}^n \frac{1}{i}
    \end{equation*}
    die $n$-te harmonische Zahl ist.
\end{thm}

\emph{Untere Schranke für Greedy-SC:} Sei $\varepsilon > 0$ sehr klein. Betrachte $n$ Knoten und $m = n + 1$ Mengen, wobei $S_i = \set{i}$ mit Kosten $\frac{1}{n+1-i}$ ist (für $i \in S$) und $S_{n+1} = S$ mit Kosten $1 + \varepsilon$. Dann wählt \textsc{Greedy-SC} wählt alle Einzelnen, OPT die gesamte Menge.

\newLecture{15.10.2025}

\begin{proof}
    \emph{Beobachtung:} Es gilt 
    \begin{equation*}
        c(A) = \sum_{x \in S} \price(x).
    \end{equation*}
    Sei $x_1, \ldots, x_n$ die Reihenfolge der Elemente in $S$, wie sie vom \textsc{Greedy-SC} abgedeckt werden (Beim Abdecken von mehreren Elementen in gleicher Iteration wähle beliebige Reihenfolge).

    \begin{lem}{Preis in Greedy-SC}{GreedySCPrice}
        Für alle $k \in \set{1,\ldots,n}$ gilt
        \begin{equation*}
            \price(x_k) \leq \frac{\OPT}{n-k+1}.
        \end{equation*}
    \end{lem}
    \begin{proof}[Beweis: Lemma~$\ref{lem:GreedySCPrice}$]
        Betrachte ein beliebiges $k \in \set{1,\ldots,n}$. Sei $i \in \set{1,\ldots,m}$ der Index der Menge $S_i$, mit der $x_k$ erstmalig abgedeckt wird. Bezeichne $A$ die Auswahl der Mengen, \emph{bevor} $x_k$ abgedeckt wird.

        Sei $C := \bigcup_{i \in A} S_i$. Es gilt $\abs{C} \leq k - 1$. Eine optimale Auswahl $A^*$ von Mengen deckt ganz $S$ ab, insbesondere auch $S \setminus C$, wobei $\abs{S \setminus C} \geq n - k + 1$.

        Es gilt 
        \begin{equation*}
            \begin{split}
                \OPT &= \sum_{j \in A^*} c_j \geq \sum_{\substack{j \in A^* \\ S_j \setminus C \neq \emptyset}} c_j = \sum_{\substack{j \in A^* \\ S_j \setminus C \neq \emptyset}} \abs{S_j \setminus C} \underset{=r_j(C) \geq r_i(C)}{\underbrace{\frac{c_j}{\abs{S_j \setminus C}}}}  \\
                &\geq r_i(C) \underset{\geq \abs{S \setminus C}}{\underbrace{\sum_{\substack{j \in A^* \\ S_j \setminus C \neq \emptyset}} \abs{S_j \setminus C}}} \geq \underset{=\price(x_k)}{\underbrace{r_i(C)}} \cdot (n-k+1)
            \end{split}
        \end{equation*}
        wobei $r_j(C) \geq r_i(C)$ wegen der Greedy-Auswahl und 
        \begin{equation*}
            \sum_{\substack{j \in A^* \\ S_j \setminus C \neq \emptyset}} \abs{S_j \setminus C} \geq \abs{S \setminus C},
        \end{equation*}
        weil $A^*$ ganz $S \setminus C$ abdeckt.
    \end{proof}
    Nun gilt mit Lemma~\ref{lem:GreedySCPrice}
    \begin{equation*}
        \begin{split}
            c(A) &= \sum_{k = 1}^n \price(x_k) \leq \sum_{k = 1}^n \frac{\OPT}{n-k+1} = \OPT\sum_{i=1}^n \frac{1}{i} = \OPT \cdot H_n
        \end{split}
    \end{equation*}
    und Satz~\ref{thm:greedySC} ist gezeigt.
\end{proof}

\section{Scheduling auf identischen Maschinen}
\begin{prob}{Scheduling auf identischen Maschinen}{SchedulingIdenticalMachines}\index{Scheduling}\index{Scheduling!auf identischen Maschinen}
    \prblmObj{Menge $J = \set{1,\ldots,n}$ von Jobs, Menge $M = \set{1,\ldots,m}$ von Maschinen, Größen $p_j > 0$ für jeden Job $j \in J$}{Schedule $\pi: J \to M$, Last von Maschine $i$ in Schedule $\pi$: $L_i(\pi) = \displaystyle\sum_{\substack{j \in J \\ \pi(j) = i}} p_j$, Makespan $C(\pi) = \max_{i \in M} L_i(\pi)$}{Finde Schedule $\pi$ mit kleinstem Makespan}
\end{prob}

\begin{algorithm}[H]
    \caption{\textsc{LeastLoaded}}\label{alg:leastloaded}\index{LeastLoaded}
    \begin{algorithmic}[1]
        \Input{Siehe~\Cref{prob:SchedulingIdenticalMachines}}
        \Output{Siehe~\Cref{prob:SchedulingIdenticalMachines}}
        \State{Betrachte Jobs in Reihenfolge $1,\ldots,n$}
        \State{Weise jedem Job der Maschine mit bislang kleinster Last zu}
    \end{algorithmic}
\end{algorithm}

\begin{thm}{LeastLoaded}{LeastLoaded}
    \textsc{LeastLoaded} ist ein $(2-\frac{1}{m})$-Approximationsalgorithmus für Scheduling auf identischen Maschinen.
\end{thm}

\begin{proof}
    Sei $\pi^*$ ein optimaler Schedule. Dann ist 
    \begin{equation*}
        C(\pi^*) \geq \frac{1}{m}\sum_{j \in J}  p_j,
    \end{equation*}
    denn
    \begin{equation*}
        C(\pi^*) = \max_{i \in M} \sum_{\substack{j \in J \\ \pi(j) = i}} p_j \geq \frac{1}{m}\sum_{i \in M}\sum_{\substack{j \in J \\ \pi(j) = i}} = \frac{1}{m}\sum_{j \in J} p_j.
    \end{equation*}
    Außerdem gilt $C(\pi^*) \geq\displaystyle\max_{j \in J} p_j$.

    Sei $\pi$ der Schedule, der \textsc{LeastLoaded} berechnet. Sei $i$ die Maschine mit größter Last. Sei $j$ der Job, der zuletzt zu $i$ hinzugefügt wurde. Zu diesem Zeitpunkt war Maschine $i$ diejenige mit der geringsten Last. Ihre Last war höchstens $\frac{1}{m}\sum_{k = 1}^{j-1} p_k$. Es gilt 
    \begin{equation*}
        C(\pi) = L_i(\pi) \leq \frac{1}{m}\underset{\leq\sum_{k \in J \setminus \set{j}} p_k}{\underbrace{\sum_{k = 1}^{j-1} p_k}} + p_j \leq \underset{\leq C(\pi^*)}{\underbrace{\frac{1}{m} \sum_{k \in J} p_k}} + \left( 1 - \frac{1}{m} \right) \underset{\leq C(\pi^*)}{\underbrace{p_j}} \leq \left( 2 - \frac{1}{m} \right)C(\pi^*)
    \end{equation*}
    und die Abschätzung ist gezeigt.
\end{proof}

\begin{rmk}
    $2-\frac{1}{m}$ ist eine untere Schranke für \textsc{LeastLoaded}.
    \begin{proof}
        Sei $n = m(m-1) + 1$ und $p_1 = \dots = p_{m(m-1)} = 1$ und $p_{m(m-1)+1} = m$. 

        \textsc{LeastLoaded} führt auf jeder Maschine $m-1$ Jobs der Größe $1$ durch. Auf einer Maschine wird zusätzlich ein Job der Größe $m$ ausgeführt. Somit ist der Makespan $m-1+m = 2m-1$.

        Eine optimale Belegung führt auf $m-1$ Maschinen je $m$ Jobs der Größe $1$ aus und auf der letzten Maschine einen Job der Größe $m$, wir haben also einen Makespan von $m$, und der Faktor stimmt.
    \end{proof}
\end{rmk}

\begin{algorithm}
    \caption{\textsc{LongestProcessingTime} (LPT)}\index{LongestProcessingTime}\index{LPT}
    \begin{algorithmic}[1]
        \Input{Siehe~\Cref{prob:SchedulingIdenticalMachines}}
        \Output{Siehe~\Cref{prob:SchedulingIdenticalMachines}}
        \State{Sortiere Jobs so, dass $p_1 \geq p_2 \geq \dots \geq p_n$.}
        \State{Führe \textsc{LeastLoaded} auf den sortierten Jobs aus.}
    \end{algorithmic}
\end{algorithm}
\begin{thm}{LPT}{LPT}
    \textsc{LongestProcessingTime} ist ein $\frac{4}{3}$-Approximationsalgorithmus.
\end{thm}
\begin{proof}
    Angenommen, es gäbe eine Instanz, sodass LPT einen Makespan von mehr als $\frac{4}{3} \cdot \OPT$ erreicht. Betrachte unter diesen Instanzen eine mit geringster Anzahl Jobs.
    
    Sei $i$ eine Maschine mit höchster Last in LPT-Schedule $\pi$. Sei $j$ der letzte Job, der Maschine $i$ zugewiesen wird. Es ist $j = n$, da sonst $p_1, \ldots, p_j$ ein Gegenbeispiel mit weniger Jobs wäre. Es gilt 
    \begin{equation*}
        C(\pi) = L_i(\pi) \leq \frac{1}{m}\sum_{k=1}^{n-1} p_k + p_n \leq \OPT + p_n.
    \end{equation*}
    Aus $C(\pi) > \frac{4}{3}\OPT$ folgt $p_n > \frac{1}{3}\OPT$. Da $p_1 \geq \dots \geq p_n$ folgt $p_j > \frac{1}{3}\OPT$ für alle $j \in J$. Also erhält im optimalen Schedule jede Maschine höchstens zwei Jobs. 
    
    Sei $k$ die Anzahl Jobs mit Größe $\frac{2}{3}\OPT$. Im optimalen Schedule sind $k$ Jobs alleine auf einer Maschine und $n-k$ Jobs höchstens zu zweit. 

    \begin{description}
        \item[Fall 1: $k = n$.] Also ist $n \leq m$, Job $n$ wird also einer leeren Maschine zugewiesen. 
        \item[Fall 2: $k < n$.] Zum Zeitpunkt bevor Job $n$ hinzugefügt wird, hat LPT mindestens eine Maschine mit höchstens einem Job und dieser hat Größe höchstens $\frac{2}{3}\OPT$. Wegen $p_n \leq \frac{2}{3}\OPT$ ist die Last dieser Maschine im Anschluss höchstens $\frac{4}{3}\OPT$.
    \end{description}
    Beides ist ein Widerspruch zur Annahme. $\lightning$
\end{proof}

\begin{rmk}
    $\frac{4}{3}$ ist eine untere Schranke für \textsc{LongestProcessingTime}.
    \begin{proof}
        Übungsaufgabe.
    \end{proof}
    Wir werden später sehen, dass für alle $\varepsilon > 0$ ein $(1+\varepsilon)$-Approximationsalgorithmus existiert.
\end{rmk}


\newLecture{21.10.2025}

\section{Rucksackproblem}

\begin{prob}{Rucksackproblem (Knapsack Problem, KP)}{knapsackProblem}
    \prblmObj{Kapazität $t \in \IN$, Nutzen $p_1, \ldots, p_n \in \IN$, Gewichte $w_1, \ldots, w_n \in \set{1,\ldots,t}$}{Teilmenge $A \subseteq \set{1,\ldots,n}$ mit $w(A) := \displaystyle \sum_{i \in A} w_i \leq t$}{Maximiere $p(A) := \displaystyle \sum_{i \in A} p_i$}\index{Rucksackproblem}\index{Knapsack-Problem}\index{KP}
\end{prob}

\begin{algorithm}
    \caption{\textsc{Greedy-KP}}\index{Greedy-KP}\label{alg:greedyKP}
    \begin{algorithmic}[1]
        \Input{Siehe~\Cref{prob:knapsackProblem}}
        \Output{Siehe~\Cref{prob:knapsackProblem}}
        \State{Sortiere Objekte nach Effizienz, sodass $\frac{p_1}{w_1} \geq \dots \geq \frac{p_n}{w_n}$}
        \State{$B := \emptyset$, $i := 1$}
        \While{$i \leq n$ \textbf{and} $w(B) + w_i \leq t$}
            \State{$B := B \cup \set{i}$}
            \State{$i := i + 1$}
        \EndWhile{}
        \State{Sei $i^*$ ein Objekt mit dem größten Nutzen}
        \If{$p(B) < p_{i^*}$}
            \State{$A := \set{i^*}$}
            \Else{} $A := B$
        \EndIf{}
        \State{\Return{$A$}}
    \end{algorithmic}
\end{algorithm}

\begin{thm}{Greedy-KP}{greedyKP}
    \textsc{Greedy-KP} ist ein $\frac{1}{2}$-Approximationsalgorithmus.
\end{thm}

\begin{proof}
    Sei $B := \set{1,\ldots,i}$ die im Algorithmus berechnete Menge. Falls $i = n$, gibt es nichts zu zeigen.

    Falls $i < n$, gilt $w(B) + w_{i+1} > t$. 

    \emph{Behauptung:} Es gilt $p(B) + p_{i+1} \geq \OPT$:

    Angenommen, $\OPT > p(B) + p_{i+1}$. Dann gibt es eine Menge $A' \subseteq \set{1,\ldots,n}$, für die gilt, dass $w(A') \leq t < w(B) + w_{i+1}$ und $p(A') = \OPT > p(B) + p_{i+1}$. 
    
    Betrachte $J := \set{1,\ldots,i+1} \setminus A'$ und $J' := A' \setminus \set{1,\ldots,i+1}$. Nun gilt 
    \begin{equation*}
        p(B) + p_{i+1} < p(A') = (p(B) + p_{i+1}) + p(J') - p(J) \implies p(J') > p(J)
    \end{equation*}
    und analog
    \begin{equation*}
        w(B) + w_{i+1} > w(A') = (w(B) + w_{i+1}) + w(J') - w(J) \implies w(J') < w(J).
    \end{equation*}
    Sei $r = \frac{p_{i+1}}{w_{i+1}}$, dann 
    \begin{equation*}
        p(J) \geq r \cdot w(J), \quad \quad p(J') \leq r \cdot w(J').
    \end{equation*}
    Zusammen ergibt sich 
    \begin{equation*}
        p(J) \geq r \cdot w(J) > r \cdot w(J') \geq p(J') > p(J). \quad \quad \lightning
    \end{equation*}
    Damit ist die Behauptung gezeigt und es gilt $p(B) + p_{i+1} \geq \OPT$.

    Somit gilt 
    \begin{equation*}
        p(A) = \max\set{p(B), p_{i^*}} \geq \frac{1}{2}(p(B) + p_{i^*}) \geq \frac{1}{2}(p(B) + p_{i+1}) \geq \frac{1}{2}\OPT
    \end{equation*}
    und die Aussage ist gezeigt.
\end{proof}


\chapter{Runden und dynamische Programmierung}

\begin{defi}{Approximationsschema, PTAS, FPATS}{ApproxScheme}
    Ein \emph{Approximationsschema}\index{Approximationsschema} $A$ für ein Optimierungsproblem $\Pi$ ist ein Algorithmus, der zu jeder Eingabe $(I, \varepsilon)$ mit $I \in \cI_\Pi, \varepsilon > 0$ eine Lösung $A(I, \varepsilon) \in \cS_I$ berechnet und es gilt 
    \begin{equation*}
        \begin{split}
            f(A(I,\varepsilon)) &\leq (1+\varepsilon)\OPT(I) \quad \quad \text{bei Minimierungsproblemen, bzw.} \\ 
            f(A(I,\varepsilon)) &\geq (1-\varepsilon)\OPT(I) \quad \quad \text{bei Maximierungsproblemen.}
        \end{split}
    \end{equation*}
    $A$ heißt \emph{polynomielles Approximationsschema}\index{Approximationsschema!polynomielles -} (PTAS)\index{PTAS}, wenn die Laufzeit für jedes $\varepsilon$ polynomiell in $\abs{I}$ beschränkt ist.

    $A$ heißt \emph{voll-polynomielles Approximationsschema}\index{Approximationsschema!voll-polynomielles -} (FPTAS)\index{FPATS}, wenn die Laufzeit polynomiell in $\frac{1}{\varepsilon}$ und $\abs{I}$ ist.
\end{defi}

\begin{expl}\leavevmode
    \begin{itemize}
        \item $\Theta(\abs{I}^{1/\varepsilon})$ ist PTAS, aber kein FPTAS
        \item $\Theta\left( \frac{\abs{I}^{100}}{\varepsilon^{10}} \right)$ ist ein FPTAS
    \end{itemize}
\end{expl}

\section{Rucksackproblem}

\subsection{Dynamische Programmierung}\index{Rucksackproblem}\index{KP}\index{Knapsack-Problem}

Sei $W(I,p)$ \emph{geringste} Gewicht unter allen Teilmengen von $\set{1,\ldots,i}$, die Nutzen mindestens $p$ erreichen, bzw. $\infty$, wenn das nicht möglich ist.

Falls $I \subseteq \set{1,\ldots,i}$ gilt: Falls $\sum_{i \in I} p_i \geq p$, dann ist $\sum_{i \in I} w_i \geq W(I, p)$.

Es gilt
\begin{equation*}
    \begin{split}
        W(0,p) &= \begin{cases}
            0 & p \leq 0 \\ 
            \infty & p > 0,
        \end{cases} \\
        W(1,p) &= \begin{cases}
            0 & p \leq 0 \\
            w_1 & 0 < p \leq p_1 \\
            \infty & p > p_1.
        \end{cases}
    \end{split}
\end{equation*}

Sei $P := \max_{\set{1,\ldots,n}} p_i$. Uns interessieren $W(i,p)$ für $i = 0,\ldots,n$ und $p = 0,\ldots,nP$.

\emph{Rekursionsformel für $W(i,p)$:}

Sei $I \subseteq \set{1,\ldots,i}$ diejenige Teilmenge mit minimalem Gewicht unter allen mit $\sum_{j \in I} p_j \geq p$.

\begin{description}
    \item[Fall 1: $i \notin I$.] Dann gilt $W(i,p) = W(i-1,p)$.
    \item[Fall 2: $i \in I$.] Dann betrachte $I \setminus \set{i}$. Es ist $W(I \setminus \set{i}) = W(i,p) - w(i)$ und $p(I \setminus \set{i}) \geq p - p_i$. Daraus folgt 
    \begin{equation*}
        W(i-1, p-p_i) \leq W(i,p) - w_i.
    \end{equation*}
    Umgekehrt sei $I' \subseteq \set{1,\ldots,i-1}$ diejenige Menge, die $W(i-1,p-p_i)$ liefert. Nun gilt
    \begin{equation*}
        W(I' \cup \set{i}) = W(i-1,p-p_i) + w_i, \quad \quad p(I' \cup \set{i}) = p(I') + p_i \geq p.
    \end{equation*}
    Daraus folgt, dass $W(i,p) \leq W(i-1,p-p_i) + w_i$.

    Umstellen liefert 
    \begin{equation*}
        W(i,p) = W(i-1, p-p_i) + w_i.
    \end{equation*}
\end{description}
Insgesamt ergibt sich die Rekursion 
\begin{equation*}
    W(i,p) = \min\set{W(i-1,p), W(i-1,p-p_i) + w_i}, \quad \quad W(0,p) = \begin{cases}
        \infty & p > 0 \\ 
        0 & p \leq 0.
    \end{cases}
\end{equation*}


\begin{algorithm}
    \caption{\textsc{DynKP}}\label{alg:DynKP}\index{DynKP}
    \begin{algorithmic}[1]
        \Input{Siehe~\Cref{prob:knapsackProblem}}
        \Output{Siehe~\Cref{prob:knapsackProblem}}
        \State{$P := \max_{i \in \set{1,\ldots,n}} p_i$}
        \For{$i = 1$ \textbf{to} $n$}
            \For{$p = 1$ \textbf{to} $nP$}
                \State{$W(i,p) = \min\set{W(i-1,p),W(i-1,p-p_i) + w_i}$}
            \EndFor{}
        \EndFor{}
        \State{\Return{maximales $p \in \set{1,\ldots,nP}$ mit $W(n,p) \leq t$.}}
    \end{algorithmic}
\end{algorithm}

\begin{thm}{DynKP}{DynKP}
    \textsc{DynKP} liefert in Zeit $\Theta(n^2 P)$ den maximal erreichbaren Nutzen.
\end{thm}

\subsection{Approximationsschema}
\begin{algorithm}
    \caption{\textsc{FPTAS-KP}}\label{alg:FPTAS-KP}\index{FPTAS-KP}
    \begin{algorithmic}[1]
        \Input{Siehe~\Cref{prob:knapsackProblem}, $\varepsilon > 0$}
        \Output{Siehe~\Cref{prob:knapsackProblem}}
        \State{$P := \max_{i \in 1,\ldots,n} p_i$}
        \State{$K := \frac{\varepsilon P}{n}$}
        \For{$i = 1$ \textbf{to} $n$}
            \State{$p_i' = \floor*{\frac{p_i}{K}}$}
        \EndFor{}
        \State{Benutze \textsc{DynKP} auf $p_1', \ldots, p_n', w_1, \ldots, w_n, t$}
    \end{algorithmic}
\end{algorithm}

\begin{thm}{FPTAS-KP}{FPTAS-KP}
    \textsc{FPTAS-KP} hat eine Laufzeit von $\cO(\frac{n^3}{\varepsilon})$ und berechnet eine $1-\varepsilon$-Approximation.
\end{thm}
\begin{proof}\leavevmode
    \begin{description}
        \item[Laufzeit:] \textsc{DynKP} braucht Zeit $\Theta(n^2 P')$, wobei $P' = \max_{i \in \set{1,\ldots,n}} p_i'$. Es gilt für alle $i$:
        \begin{equation*}
            p_i' = \floor*{\frac{p_i}{K}} \leq \floor*{\frac{P}{K}} = \floor*{\frac{n}{\varepsilon}} \leq \frac{n}{\varepsilon},
        \end{equation*}
        also ist auch $P' \leq \frac{n}{\varepsilon}$.
        \item[Approximationsfaktor:] Sei $I'$ eine optimale Lösung auf $p_1', \ldots, p_n'$ und $I$ eine optimale Lösung auf $p_1, \ldots, p_n$.
        
        $I'$ ist auch eine optimale Lösung auf $\set{p_i^*} := \set{K \cdot p_i'}$.
        \begin{expl}
            Für $n = 4, P = 50, \varepsilon = \frac{4}{5}, K = \frac{\varepsilon P}{n} = 10$. Für $p_1 = 33$ erhalten wir $p_1' = 3$ bzw. $p_1^* = 30$.
        \end{expl}

        Es gilt $p_i^* = K \cdot \floor*{\frac{p_i}{K}} \geq K \cdot \left( \frac{p_i}{K} - 1 \right) = p_i - K$ und $p_i^* \leq K \cdot \frac{p_i}{K} = p_i$, also $p_i^* \in \edgys{p_i - K, p_i}$.

        Für alle $J \subseteq \set{1,\ldots,n}$ gilt 
        \begin{equation*}
            p^*(J) := \sum_{i \in J} p_i^* \leq \sum_{i \in J} p_i = p(J)
        \end{equation*}
        und 
        \begin{equation*}
            p^*(J) = \sum_{i \in J} p_i^* \geq \sum_{i \in J} (p_i - K) = \sum_{i \in J} p_i - \abs{J} \cdot K \geq p(J) - nK.
        \end{equation*}
        Damit ist $p(I') \geq p^*(I') \geq p^*(I) \geq p(I) - nK$, da $I'$ optimal hinsichtlich $p^*$ ist.

        Weiterhin ist $p(I) \geq P$, also gilt 
        \begin{equation*}
            \frac{p(I')}{\OPT} \geq \frac{p(I) - nK}{p(I)} \geq 1 - \frac{nK}{P} = 1 - \varepsilon
        \end{equation*}
        und wir erhalten $1-\varepsilon$ als Approximationsfaktor.
    \end{description}
\end{proof}

\newLecture{22.10.2025}

\section{Scheduling auf identischen Maschinen}\index{Scheduling}\index{Scheduling!auf identischen Maschinen}

\emph{Erster Ansatz für Approximationsschema:} Wir nennen einen Job $j \in J$ \emph{klein}, falls 
\begin{equation*}
    p_j \leq \varepsilon \cdot \frac{1}{m} \sum_{k = 1}^n p_k,
\end{equation*}
sonst heißt er \emph{groß}. Wir betrachten folgenden Algorithmus:

\begin{algorithm}
    \caption{\textsc{GroßKleinScheduling}}\label{alg:grossKlein}
    \begin{algorithmic}[1]
        \Input{Siehe~\Cref{prob:SchedulingIdenticalMachines}, $\varepsilon > 0$}
        \Output{Siehe~\Cref{prob:SchedulingIdenticalMachines}}
        \State{Berechne optimalen Schedule auf großen Jobs} \Comment{Bspw. durch Ausprobieren aller Schedules}
        \State{Ergänze kleine Jobs mit \textsc{LeastLoaded}}
    \end{algorithmic}
\end{algorithm}

\begin{thm}{GroßKleinScheduling}{grossKlein}
    \textsc{GroßKleinScheduling} ist ein PTAS mit Laufzeit $m^{\frac{m}{\varepsilon}}$.
\end{thm}

\begin{proof}
    \begin{description}
        \item[Laufzeit:] Für Algorithmus~\ref{alg:grossKlein} gibt es höchstens $\frac{m}{\varepsilon}$ große Jobs, denn jeder ist mindestens $\varepsilon\frac{1}{m}\sum_{k=1}^n p_k$ groß. Damit gibt es maximal $m^{\frac{m}{\varepsilon}}$ mögliche Schedules. Damit hat Algorithmus~\ref{alg:grossKlein} polynomielle Laufzeit für jedes $\varepsilon > 0$, wenn $m$ konstant ist.
        \item[Approximationsfaktor:] Betrachte die Maschine mit der größten Last.
        \begin{description}
            \item[Fall 1:] Diese Maschine erhält nur große Jobs in unserem Schedule. Dann ist der Makespan durch die kleinen Jobs unverändert. Unser Schedule ist optimal auf den großen Jobs, und somit auch optimal auf allen Jobs.
            \item[Fall 2:] Diese Maschine erhält auch einen kleinen Job. Im Moment der Zuweisung des letzten solchen Jobs durch \textsc{LeastLoaded} ist die Last höchstens die $\frac{1}{m}\sum_{k=1}^n p_k$. Der letzte Job ist ein kleiner Job, somit haben wir am Ende eine Gesamtlast von höchstens 
            \begin{equation*}
                (1+\varepsilon)\frac{1}{m}\sum_{k=1}^n p_k \leq (1+\varepsilon)\OPT.
            \end{equation*}
        \end{description}
    \end{description}
\end{proof}

\subsection{Bin-Packing mit konstant vielen Objektgrößen}

\begin{prob}{Bin-Packing}{binPacking}\index{Bin-Packing}
    \prblmObj{Objektgrößen $s_1, \ldots, s_n \in \IN$, Kapazität $T \in \IN$}{Partitionen $C_1, \ldots, C_\ell$ der Menge $\set{1,\ldots,n}$ mit $\sum_{j \in C_i} s_j \leq T$ für alle $i$}{Minimiere $\ell$}
\end{prob}

\emph{Spezialfall:} Wir wählen als Eingabe $(s_1, \ldots, s_z) \in \IN^z, (n_1, \ldots, n_z) \in \IN^z, T \in \IN$. Dabei haben wir jeweils $n_i$ Objekte der Größe $s_i$.

Wir bezeichnen mit $\BINS(i_1, \ldots, i_z)$ den optimalen Zielfunktionswert, wenn es $i_j \leq n_j$ Objekte der Größe $s_j$ gibt. Uns interessiert $\BINS(n_1, \ldots, n_z)$. Berechne aller Werte $\BINS(i_1, \ldots, i_z)$ für $(i_1, \ldots, i_z) \in \IN_0^z$ mit $i_j \leq n_j$. Wenn $z$ konstant ist, gibt es höchstens $(n+1)^z \in \cO(n^z)$ viele solche Vektoren.

Definiere 
\begin{equation*}
    C := \set*{(i_1, \ldots, i_z) \in \IN_0^z ~\middle|~ \sum_{j = 1}^z i_j s_j \leq T} \setminus \set{(0,\ldots,0)}.
\end{equation*}

Wir bemerken:
\begin{itemize}
    \item $\BINS(0,\ldots,0) = 0$
    \item $\BINS(i_1, \ldots, i_z) = 1$ für $(i_1, \ldots, i_z \in C)$
\end{itemize}
Für die allgemeine Größe von $\BINS(i_1, \ldots, i_z)$ betrachte ein optimales Packing. Der erste Bin erhalte $(c_1, \ldots, c_z) \in C$ viele Objekte. So erhalten die übrigen Bins insgesamt $(i_1 - c_1, \ldots, i_z - c_z)$ Objekte und es gilt 
\begin{equation*}
    \BINS(i_1, \ldots, i_z) = 1 + \BINS(i_1 - c_1, \ldots, i_z - c_z).
\end{equation*}
Als allgemeine Rekursionsformel ergibt sich 
\begin{equation*}
    \BINS(i_1, \ldots, i_n) = 1 + \min_{(c_1, \ldots, c_z) \in C} \BINS(i_1 - c_1, \ldots, i_z - c_z) \quad \quad \text{für alle } (i_1, \ldots, i_z) \neq (0, \ldots, 0)
\end{equation*}
und $\BINS(0,\ldots,0) = 0$.

Wir berechnen Werte von $\BINS(i_1, \ldots, i_z)$ aufsteigend nach $\sum_{j=1}^z i_j$. Insgesamt werden $\cO(n^z)$ viele Vektoren mit jeweils Laufzeit $\cO(n^z)$ pro Vektor, damit ergibt sich eine Gesamtlaufzeit von $\cO(n^{2z})$, also folgender Satz:

\begin{thm}{Bin-Packing}{binPacking}
    Das Bin-Packing-Problem mit $z$ verschiedenen Objektgrößen kann für Instanzen mit $n$ Objekten in Zeit $\cO(n^{2z})$ gelöst werden (wobei die Konstante in der $\cO$-Notation von $z$ abhängt.) 
\end{thm}

\subsection{Approximationsschema}

\emph{Zusätzliche Eingabe:} $T$. Der Algorithmus liefert entweder einen Schedule mit Makespan höchstens $(1+\varepsilon)T$ oder er beweist, dass $\OPT > T$. 

Wir bezeichnen einen Job $j$ als \emph{groß}, falls $p_j > \varepsilon T$. Wir runden die Größen aller großen Jobs auf Vielfache von $\varepsilon^2 T$ ab, somit gibt es höchstens $\frac{1}{\varepsilon^2}$ viele Jobgrößen. Auf diesen bestimmen wir eine optimale Bin-Packing-Lösung. Wir erhalten als Antwort entweder eine Packung der großen Jobs auf $m$ Maschinen mit Makespan $\leq T$ (bzgl. der gerundeten Jobgrößen), oder dass es nicht möglich ist (dann brechen wir ab). Für die kleinen Jobs verwenden wir anschließend \textsc{LeastLoaded}.

Für den Makespan gilt insgesamt:
\begin{itemize}
    \item Erhält eine Maschine einen kleinen Job, betrachte den letzten derartigen Job. Dann gilt 
    \begin{equation*}
        L_i(\pi) \leq \underset{\leq T}{\underbrace{\left( \frac{1}{m}\sum_{k=1}^n p_k \right)}} + p_j \leq (1+\varepsilon)T.
    \end{equation*}
    \item Erhält eine Maschine keinen kleinen Job, dann ist die Last durch die gerundeten Jobgrößen höchstens $T$. Sei $p_j'$ die abgerundete Jobgröße und $p_j$ die tatsächliche Jobgröße. Dann gilt
    \begin{equation*}
        p_j \geq \varepsilon T, \quad \quad p_j' \geq p_j - \varepsilon^2 T \geq p_j - \varepsilon p_j' \implies p_j \leq (1+\varepsilon) p_j',
    \end{equation*}
    unter der Voraussetzung, dass $\frac{1}{\varepsilon} \in \IN$.
\end{itemize}
Somit sind nicht gerundete Jobgrößen höchstens um den Faktor $(1+\varepsilon)$ größer und somit ist die Last der Maschine $\leq (1+\varepsilon) T$ bezüglich der tatsächlichen Jobgrößen.

Hier der Algorithmus nochmal in Pseudocode:
\begin{algorithm}
    \caption{$B_\varepsilon(T)$}\label{alg:BEpsilon}
    \begin{algorithmic}[1]
        \State{Sei $J' = \set{j \in J \mid p_j > \varepsilon T}$ die Menge der großen Jobs}
        \State{Für $j \in J$ sei $p_j'$ der Wert $p_j$ auf das nächste Vielfache von $\varepsilon^2 T$ abgerundet. Sei $I'$ die Instanz, die nur aus Jobs mit den Größen $p_j'$ mit $j \in J'$ besteht.}
        \State{Konstruiere eine Instanz für Bin-Packing mit Objektgrößen $\set{p_j' \mid j \in J'}$ und Kapazität $T$. Bezeichne $a$ die minimale Anzahl an Bins, die für diese Instanz benötigt werden. Berechne $a$ und die dazugehörige Verteilung $\pi'$ der Objekte mit Hilfe des dynamischen Programms aus Satz~\ref{thm:binPacking}.}
        \If{$a > m$} 
        \State{\Return{$\OPT(I) \geq \OPT(I') > T$}}
        \Else{} 
        \State{Erweitere $\pi'$ auf alle Jobs aus $J$ durch Hinzufügen der Jobs aus $J \setminus J'$ mittels \textsc{LeastLoaded}.}
        \State{\Return{resultierenden Schedule $\pi$}}
        \EndIf{}
    \end{algorithmic}
    
\end{algorithm}

Somit haben wir gezeigt:
\begin{lem}{$B_\varepsilon(T)$}{BEpsilon}
    Es gibt einen Algorithmus, der in Zeit $\cO(n^{\frac{2}{\varepsilon^2}})$ entweder beweist, dass es keinen Schedule mit Makespan $T$ gibt oder einen Schedule mit Makespan $(1+\varepsilon)T$ berechnet.
\end{lem}
Für einen Optimalen Makespan gilt num 
\begin{equation*}
    \begin{split}
        \OPT &\geq \ceil*{\frac{1}{m}\sum_{k=1}^n p_k} \\
        \OPT &\geq p_{\max} \\
        \OPT &\leq \ceil*{\frac{1}{m}\sum_{k=1}^n p_k} + p_{\max}.
    \end{split}
\end{equation*}
Setze initial $L := \max\set*{\ceil*{\frac{1}{m}\sum_{k=1}^n p_k}, p_{\max}}$ und $U := \ceil*{\frac{1}{m}\sum_{k=1}^n p_k} + p_{\max}$. Dabei haben wir folgende Invarianten:
\begin{enumerate}
    \item $L \leq \OPT$
    \item Wir können einen Schedule mit Makespan höchstens $(1+\varepsilon)U$ in Zeit $\cO(n^{\frac{2}{\varepsilon^2}})$ berechnen.
\end{enumerate}
Nun berechne $T := \floor*{\frac{L + U}{2}}$ und prüfe, ob ein Schedule mit Makespan $T$ berechnet werden kann. Falls ja, setze $U := T$, sonst setze $L := T + 1$. Es gilt $U - L \leq \frac{p_{\max}}{2^i}$ nach $i$ Iterationen, somit gilt $U - L \leq \frac{1}{2}$ nach $ \floor*{\log_2(p_{\max})}+1$ Iterationen. Dann muss $L = U$ gelten und wir erhalten als Resultat folgenden Satz:

\begin{thm}{PTAS Scheduling}{PTASScheduling}
    Für Scheduling auf identischen Maschinen existiert ein PTAS mit einer Laufzeit von $\cO(m^{\frac{2}{\varepsilon^2}}\log(p_{\max}))$.
\end{thm}

\newLecture{28.10.2025}

\subsection{Untere Schranke für Approximierbarkeit}

\begin{defi}{Stark NP-schwer}{stronglyNPhard}
    Sei $\Pi$ ein Optimierungsproblem, in dessen Instanzen ganze Zahlen enthalten sind. $\Pi$ heißt \emph{stark NP-schwer}\index{stark NP-schwer}, wenn es ein Polynom $q$ gibt, sodass $\Pi$ eingeschränkt auf Instanzen $I$, in denen alle Zahlen durch $q(\abs{I})$ beschränkt sind, bereits NP-schwer ist.
\end{defi}

Scheduling auf identischen Maschinen ist tatsächlich stark NP-schwer.

\begin{thm}{Scheduling hat keinen FPTAS}{schedulingNoFPTAS}
    Unter der Annahme $\mathrm{P} \neq \mathrm{NP}$ existiert kein FPTAS für Scheduling auf identischen Maschinen.
\end{thm}
\begin{proof}
    Angenommen, es gäbe einen FPTAS. Weil Scheduling auf identischen Maschinen stark NP-schwer ist, gibt es ein Polynom $q$, sodass es bereits NP-schwer ist, das Problem mit Jobgrößen $p_1 \leq \cdots \leq p_n \in \set{1,\ldots, q(n)}$ zu lösen.

    Berechne mit dem FPTAS eine $(1+\varepsilon)$-Approximation, wobei $\varepsilon = \frac{1}{2nq(n)}$. Die Laufzeit ist polynomiell in $n$ und $\frac{1}{\varepsilon} = 2nq(n)$, also beides polynomiell in $n$. Für den Approximationsfaktor erhalten wir $w_A(I, \varepsilon) \leq (1+\varepsilon) \OPT$.
    Es gilt 
    \begin{equation*}
        \OPT(I) \leq \sum_{i = 1}^n p_i \leq n \cdot q(n)
    \end{equation*}
    und folglich 
    \begin{equation*}
        (1+\varepsilon)\OPT = \OPT + \underset{\leq \frac{1}{2}}{\underbrace{\varepsilon\OPT}}  \leq \OPT(I) + \varepsilon n q(n) = \OPT + \frac{1}{2}.
    \end{equation*}
    Weil alle Jobgrößen ganzzahlig sind, sind auch $w_A(I, \varepsilon)$ und $\OPT(I)$ ganze Zahlen. Da die Differenz höchstens $\frac{1}{2}$ ist, ist $w_A(I, \varepsilon) = \OPT(I)$. Also löst der FPTAS das Problem exakt in polynomieller Zeit. Also muss $\mathrm{P} = \mathrm{NP}$ sein. $\lightning$ zur Annahme
\end{proof}

\chapter{Randomisierte Approximationsalgorithmen}

\begin{prob}{Maximum-Cut Problem}{MaxCut}\index{MaxCut}
    \prblmObj{Ungerichteter Graph $G = (V, E)$, Kantengewichte $w: E \to \IR_{> 0}$}{Menge $U \subseteq V$. Wir nennen $(U, V \setminus U)$ \emph{Schnitt} des Graphen $G$}{Maximiere $\displaystyle\sum_{x \in U} \sum_{y \in V \setminus U} w(x,y)$ mit $w(x,y) = 0$, falls $\set{x,y} \notin E$.}
\end{prob}

\begin{algorithm}
    \caption{\textsc{RandMaxCut}}\label{alg:RandMaxCut}
    \begin{algorithmic}[1]
        \Input{Wie in~\Cref{prob:MaxCut}}
        \Output{Wie in~\Cref{prob:MaxCut}}
        \State{$U := \emptyset$}
        \For{$v \in V$}
            \State{Wirf eine Münze}
            \If{Münze zeigt Kopf} 
                \State{Füge $v$ zu $U$ hinzu} 
            \EndIf{}
        \EndFor{}
        \State{\Return $U$}
    \end{algorithmic}
\end{algorithm}


\section{Grundlagen der Wahrscheinlichkeitsrechnung}

\subsection{Diskrete Wahrscheinlichkeitsräume}

\begin{defi}{Wahrscheinlichkeitsraum}{probabilitySpace}
    Sei $\Omega$ eine endliche oder abzählbare Menge (\emph{Ergebnismenge})\index{Wahrscheinlichkeitsraum!Ergebnismenge $\Omega$}\index{Ergebnismenge $\Omega$}. 
    
    Elemente von $\Omega$ heißen \emph{Elementarereignisse}\index{Elementarereignis}\index{Wahrscheinlichkeitsraum!Elementarereignis}, Teilmengen von $\Omega$ heißen \emph{Ereignisse}\index{Ereignis}\index{Wahrscheinlichkeitsraum!Ereignis}.

    Für $A \subseteq \Omega$ bezeichne $\overline{A} := \Omega \setminus A$ das \emph{Gegenereignis}\index{Ereignis!Gegen-}.

    Ein(-e) \emph{Wahrscheinlichkeit(-smaß)}\index{Wahrscheinlichkeit}\index{Wahrscheinlichkeitsmaß}\index{Wahrscheinlichkeitsraum!Wahrscheinlichkeit}\index{Wahrscheinlichkeitsraum!Wahrscheinlichkeitsmaß} ist eine Funktion $\IP: 2^\Omega \to \edgys{0,1}$ mit $\IP[\Omega] = 1$ und $\IP$ \emph{$\sigma$-additiv}\index{sigma@$\sigma$-additiv}\index{Wahrscheinlichkeitsraum!sigma@$\sigma$-additiv}, d.h. für $A_1, A_2, \ldots \subseteq \Omega$ mit $A_i \cap A_j = \emptyset$ für $i \neq j$ gilt 
    \begin{equation*}
        \IP\left[ \bigcup_{i=1}^\infty A_i \right] = \sum_{i=1}^\infty \IP[A_i].
    \end{equation*}

    Das Paar $(\Omega, \IP)$ heißt (diskreter) \emph{Wahrscheinlichkeitsraum}\index{Wahrscheinlichkeitsraum}.
\end{defi}

Es reicht, $\IP[a]$ für alle $a \in \Omega$ zu definieren, denn 
\begin{equation*}
    \IP[\set{a_1, \ldots, a_n}] = \sum_{i = 1}^n \IP[\set{a_i}].
\end{equation*}

\begin{expl}
    Bei einem Würfelwurf setze $\Omega = \set{1,\ldots, 6}$. Dann ist $\IP[i] = \frac{1}{6}$ für alle $i \in \Omega$. Es ist auch $\IP[\text{\enquote{gerade Zahl}}] = \IP[\set{2,4,6}] = 3 \cdot \frac{1}{6} = \frac{1}{2}$.
\end{expl}

Wir modellieren nun einen Wahrscheinlichkeitsraum für \textsc{RandMaxCut}:

Sei $V = \set{v_1, \ldots, v_n}$. Setze $\Omega = \set{0,1}^n$. Wir berechnen den Schnitt als 
\begin{equation*}
    U = \set{v_i \in V \mid \omega_i = 1}.
\end{equation*}
Für alle $e = \set{v_i, v_j} \in E$, ist die Wahrscheinlichkeit, dass $e$ über den Schnitt läuft, gerade $\frac{1}{2}$, denn es ist 
\begin{equation*}
    \IP[\text{$e$ läuft über den Schnitt $(U, V \setminus U)$}] = \IP[\set{\omega \in \Omega \mid \omega_i \neq \omega_j}] = \frac{2^{n-1}}{2^n} = \frac{1}{2}.
\end{equation*}

\subsection{Unabhängigkeit und bedingte Wahrscheinlichkeiten}
\begin{defi}{Unabhängige Ereignisse}{independentEvents}
    Sei $(\Omega, \IP)$ ein diskreter Wahrscheinlichkeitsraum. Zwei Ereignisse $A, B \subseteq \Omega$ heißen \emph{unabhängig}\index{Ereignis!unabhängige -se}\index{Wahrscheinlichkeitsraum!Ereignis!unabhängige -se}, falls 
    \begin{equation*}
        \IP[A \cap B] = \IP[A] \cdot \IP[B].
    \end{equation*}
    Allgemeiner: Ereignisse $A_1, \ldots, A_k \subseteq \Omega$ heißen \emph{unabhängig}, wenn für alle $I \subseteq \set{1,\ldots,k}$ gilt 
    \begin{equation*}
        \IP\left[ \bigcap_{i \in I} A_i \right] = \prod_{i \in I} \IP[A_i].
    \end{equation*}
\end{defi}

\begin{expl}\leavevmode
    \begin{itemize}
        \item Sei $\Omega = \set{(i, j) \mid i, j \in \set{1,\ldots,6}}$. Dann ist $\IP[(i,j)] = \frac{1}{36}$. 
        
        Seien $A := \text{\enquote{Erster Würfel zeigt eine gerade Zahl}}$ und $B := \text{\enquote{Zweiter Würfel zeigt $\geq 3$}}$. Dann ist $\IP[A] = \frac{1}{2}, \IP[B] = \frac{2}{3}$ und $\IP[A \cap B] = \frac{1}{3} = \IP[A] \cdot \IP[B]$. Also sind $A$ und $B$ unabhängig.
        \item Für eine endlihce Folge von Wahrscheinlichkeitsräumen $(\Omega_1, \IP_1), \ldots, (\Omega_n, \IP_n)$ definieren wir den \emph{Produktraum}\index{Wahrscheinlichkeitsraum!Produktraum} durch $\Omega := \Omega_1 \times \cdots \times \Omega_n$ und $\IP[(x_1, \ldots, x_n)] := \IP_1[x_1] \cdot \ldots \cdot \IP_n[x_n]$.
    \end{itemize}
\end{expl}
In \textsc{RandMaxCut} ist der Wahrscheinlichkeitsraum eigentlich ein Produktraum von $n$ Münzwürfen $(\set{0,1},\IP)$ mit $\IP[0] = \IP[1] = \frac{1}{2}$. Seien $e, e' \in E$ ohne gemeinsame Endpunkte. Dann ist
\begin{equation*}
    \IP[\text{\enquote{$e$ und $e'$ laufen über Schnitt}}] = \frac{1}{4} = \IP[\text{\enquote{$e$ läuft über Schnitt}}] \cdot \IP[\text{\enquote{$e'$ läuft über Schnitt}}].
\end{equation*}

\begin{defi}{Bedingte Wahrscheinlichkeit}{condProb}
    Sei $(\Omega, \IP)$ ein diskreter Wahrscheinlichkeitsraum. Seien $A, B \subseteq \Omega$ mit $\IP[B] > 0$. Dann bezeichne 
    \begin{equation*}
        \IP[A \mid B] := \frac{\IP[A \cap B]}{\IP[B]}
    \end{equation*}
    die \emph{bedingte Wahrscheinlichkeit} von $A$ gegeben $B$.\index{Wahrscheinlichkeit!bedingte -}\index{bedingte Wahrscheinlichkeit}
\end{defi}

\begin{expl}
    Wir betrachten zwei unanbhängige Würfelwürfe. Sei $A := \text{\enquote{Erster Würfel zeigt $6$}}$ und $B := \text{\enquote{Summe beider Würfe ist $10$}}$. Dann sind 
    \begin{equation*}
        \IP[A] = \frac{1}{6}, \quad \IP[B] = \frac{3}{36}, \quad \IP[A \cap B] = \frac{1}{36} \quad \text{und} \quad \IP[A \mid B] = \frac{1}{3}.
    \end{equation*}
\end{expl}

\section{Zufallsvariablen und Erwartungswerte}

\begin{defi}{Zufallsvariable}{randomVar}
    Sei $(\Omega, \IP)$ ein diskreter Wahrscheinlichkeitsraum. eine Abbildung $X: \Omega \to \IR$ heißt (diskrete, reelle) \emph{Zufallsvariable}\index{Zufallsvariable}. Wir schreiben 
    \begin{equation*}
        \IP[X = a] = \IP[\set{\omega \in \Omega \mid X(\omega) = a}] 
    \end{equation*}
    und allgemeiner 
    \begin{equation*}
        \IP[X \in A] = \IP[\set{\omega \in \Omega \mid X(\omega) \in A}].
    \end{equation*}
\end{defi}

\begin{expl}
    Betrachte zwei unabhängige Würfelwürfe. Sei $X: \Omega := \set{1,\ldots,12}$ definiert durch $X(\omega) := \omega_1 + \omega_2$ für alle $\omega = (\omega_1, \omega_2) \in \Omega$.
\end{expl}

\begin{defi}{Unabhängigkeit (Zufallsvariablen)}{independentRandomVar}
    Seien $X, Y: \Omega \to \IR$ Zufallsvariablen. $X$ und $Y$ heißen \emph{unabhängig}\index{Unabhängigkeit}\index{Zufallsvariable!unabhängige -n}\index{Unabhängigkeit!von Zufallsvariablen}, wenn für alle $x,y \in \IR$ gilt
    \begin{equation*}
        \IP[(X = x) \cap (Y = y)] = \IP[X = x] \cdot \IP[Y = y].
    \end{equation*}
    Allgemeiner seien $X_1, \ldots, X_n : \Omega \to \IR$ Zufallsvariablen. Diese heißen \emph{unabhängig}, wenn für alle $I \subseteq \set{1,\ldots,n}, x_i \in \IR$ gilt 
    \begin{equation*}
        \IP\left[ \bigcap_{i \in I} (X_i = x) \right] = \prod_{i \in I} \IP[X_i = x].
    \end{equation*}
\end{defi}

\begin{defi}{Erwartungswert}{expectedValue}
    Sei $X: \Omega \to \IR$ eine diskrete Zufallsvariable. Falls die Reihe 
    \begin{equation*}
        \sum_{\omega\in \Omega} \abs{X(\omega)} \cdot \IP[\omega]
    \end{equation*}
    konvergiert, heißt 
    \begin{equation*}
        \IE[X] := \sum_{\omega \in \Omega} X(\omega) \cdot \IP[\omega]
    \end{equation*}
    \emph{Erwartungswert}\index{Erwartungswert}\index{Zufallsvariable!Erwartungswert} von $X$.
\end{defi}

\newLecture{29.10.2025}


\end{document}